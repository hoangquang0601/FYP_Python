{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:42:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Training XGBoost: 100%|██████████| 1/1 [02:16<00:00, 136.41s/it]\n",
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:50:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8971714613111392\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.83      0.51      0.63      1045\n",
      "         NEU       0.90      0.96      0.93     11197\n",
      "         POS       0.89      0.84      0.86      4339\n",
      "\n",
      "    accuracy                           0.90     16581\n",
      "   macro avg       0.87      0.77      0.81     16581\n",
      "weighted avg       0.90      0.90      0.89     16581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('labelled_data.csv')\n",
    "\n",
    "# Prepare text data\n",
    "texts = df['Comment Text']\n",
    "labels = df['Sentiment Label']\n",
    "\n",
    "# Map the sentiment labels to numerical values\n",
    "label_mapping = {'NEG': 0, 'NEU': 1, 'POS': 2}\n",
    "labels = labels.map(label_mapping)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectorizer and transform the text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize individual models\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Initialize and train the XGBoost classifier with progress bar\n",
    "xgb_clf = XGBClassifier(learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.7, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "for _ in tqdm(range(1), desc=\"Training XGBoost\"):\n",
    "    xgb_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
    "    voting='soft'  # 'soft' voting uses predicted probabilities for classification\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ensemble_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['NEG', 'NEU', 'POS'])\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:04:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Training XGBoost: 100%|██████████| 1/1 [01:49<00:00, 109.25s/it]\n",
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:20:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:29:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:37:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:45:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:54:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.89807765 0.8977761  0.8928006  0.88986054 0.89882388]\n",
      "Mean cross-validation accuracy: 0.8954677546005911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chummy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:00:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8975333212713347\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.83      0.51      0.64      1045\n",
      "         NEU       0.90      0.96      0.93     11197\n",
      "         POS       0.89      0.84      0.86      4339\n",
      "\n",
      "    accuracy                           0.90     16581\n",
      "   macro avg       0.87      0.77      0.81     16581\n",
      "weighted avg       0.90      0.90      0.89     16581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('labelled_data.csv')\n",
    "\n",
    "# Prepare text data\n",
    "texts = df['Comment Text']\n",
    "labels = df['Sentiment Label']\n",
    "\n",
    "# Map the sentiment labels to numerical values\n",
    "label_mapping = {'NEG': 0, 'NEU': 1, 'POS': 2}\n",
    "labels = labels.map(label_mapping)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectorizer and transform the text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize individual models\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Initialize and train the XGBoost classifier with progress bar\n",
    "xgb_clf = XGBClassifier(learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.7, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "for _ in tqdm(range(1), desc=\"Training XGBoost\"):\n",
    "    xgb_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
    "    voting='soft'  # 'soft' voting uses predicted probabilities for classification\n",
    ")\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_results = cross_val_score(ensemble_clf, X_train_tfidf, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f'Cross-validation accuracy scores: {cv_results}')\n",
    "print(f'Mean cross-validation accuracy: {cv_results.mean()}')\n",
    "\n",
    "# Train the ensemble model on the entire training set\n",
    "ensemble_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ensemble_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['NEG', 'NEU', 'POS'])\n",
    "\n",
    "print(f'Accuracy on test set: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
